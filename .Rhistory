#building descision tree
#install.packages("rpart")
library(rpart)
fit <- rpart(seedsclassTrain~., method="class", data=seedsvaluesTrain) #model for decision tree
#Plot descision tree for seedsdata
plot(fit, uniform=TRUE, main="Decision Tree for Seedsdata")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
#classifier test / checking accuracy
treepred <-predict(fit, seedsvaluesTest, type = 'class')
n = length(seedsclassTest) #the number of test cases in the length of the testdata
ncorrect = sum(treepred==seedsclassTest) #the number of correctly predicted
accuracy=ncorrect/n
print(accuracy)
#viewing results as table
table_mat = table(seedsclassTest, treepred)
print(table_mat)
#vewing effect of pruning/plotting pruned dexision trees with a pruning parameter here, cp, set to 0.1
#REMOVING UNWANTED BRANCHES TO AVOID OVERFITTING
pfit1<- prune(fit, cp=0.1)
#vewing effect of pruning/with a pruning parameter here, cp, set to 0.3
pfit2<- prune(fit, cp=0.3)
#vewing effect of pruning/with a pruning parameter here, cp, set to 0.6
pfit3<- prune(fit, cp=0.6)
#testing the classifier on the test set by calculating the predictions for each testcase in our test set
ppred1 <- predict(pfit1, seedsvaluesTest, type = "class")
ppred2 <- predict(pfit2, seedsvaluesTest, type = "class")
ppred3 <- predict(pfit3, seedsvaluesTest, type = "class")
l = length(seedsclassTest)
lcor1 = sum(ppred1 == seedsclassTest)
lcor2 = sum(ppred2 == seedsclassTest)
lcor3 = sum(ppred3 == seedsclassTest)
lacc1 = lcor1/l #with a pruning parameter here, cp, set to 0.1
lacc2 = lcor2/l #with a pruning parameter here, cp, set to 0.3
lacc3 = lcor3/l #with a pruning parameter here, cp, set to 0.6
#declaring variables of decision tree
accuracyDT <- c(lacc1,lacc2,lacc3)
cpVAL <-c(0.1, 0.3, 0.6)
#plotting pruned tree
plot(pfit, uniform = TRUE, main="Pruned deision tree CP=0.1)")
text(pfit, use.n = TRUE, all = TRUE, cex =0.5)
#Task 3: Plot 2 variables (class and area)
plot(seedsclass, seeds_rand$Area, main = "Area against class", ylab="area", xlab = "seeds class", col = ifelse(seedsclass == 1, "green", ifelse(seedsclass == 2, "red", "blue")))
#Task 4:Compare the accuracy of the different pruned trees to KNN with different values of k
library(class)
#generating predicated classes k=number of clusters
knnpred1 = knn(seedsvaluesTrain, seedsvaluesTest, seedsclassTrain, k=1)
knnpred2 = knn(seedsvaluesTrain, seedsvaluesTest, seedsclassTrain, k=3)
knnpred3 = knn(seedsvaluesTrain, seedsvaluesTest, seedsclassTrain, k=6)
k = length(seedsclassTest)
kcor1 = sum(knnpred1 == seedsclassTest)
kcor2 = sum(knnpred2 == seedsclassTest)
kcor3 = sum(knnpred3 == seedsclassTest)
kacc1 = kcor1 / k
kacc2 = kcor2 / k
kacc3 = kcor3 / k
print(kacc1)
print(lacc2)
#declared variables of KNN
knnAccRes <- c(kacc1, kacc2, kacc3)
noClusters<- c(1,3,6)
#comparing knn and dynamic trees plots
plot(noClusters,knnAccRes, ylab = "k-nearest accuracy", xlab = "number of clusters", main = "accuracy against clusters")
plot(cpVAL, accuracyDT, ylab = "decision tree accuracy", xlab = "CP values", main="accuracy of pruned data")
seedsdata = read.csv('/Users/elias/Downloads/seeds_dataset_class (1).csv', sep=",")
#randomize - we do not want to train an ordered dataset, highly unlikely to get higher accuracy, no possibility of backtracking
seeds_rand=seedsdata[sample(209,209),]
#separate the class and values into separate variables
seedsclass = seeds_rand[,1]
seedsvalues = seeds_rand[,-1]
#set up a training set - split data into a larger portion for training
seedsclassTrain = seedsclass[1:150]
seedsvaluesTrain = seedsvalues[1:150,]
#and testset - split data into a smaller portion for testset
seedsclassTest = seedsclass[150:209]
seedsvaluesTest = seedsvalues[150:209,]
#building descision tree
#install.packages("rpart")
library(rpart)
fit <- rpart(seedsclassTrain~., method="class", data=seedsvaluesTrain) #model for decision tree
#Plot descision tree for seedsdata
plot(fit, uniform=TRUE, main="Decision Tree for Seedsdata")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
#classifier test / checking accuracy
treepred <-predict(fit, seedsvaluesTest, type = 'class')
n = length(seedsclassTest) #the number of test cases in the length of the testdata
ncorrect = sum(treepred==seedsclassTest) #the number of correctly predicted
accuracy=ncorrect/n
print(accuracy)
#viewing results as table
table_mat = table(seedsclassTest, treepred)
print(table_mat)
#vewing effect of pruning/plotting pruned dexision trees with a pruning parameter here, cp, set to 0.1
#REMOVING UNWANTED BRANCHES TO AVOID OVERFITTING
pfit1<- prune(fit, cp=0.1)
#vewing effect of pruning/with a pruning parameter here, cp, set to 0.3
pfit2<- prune(fit, cp=0.3)
#vewing effect of pruning/with a pruning parameter here, cp, set to 0.6
pfit3<- prune(fit, cp=0.6)
#testing the classifier on the test set by calculating the predictions for each testcase in our test set
ppred1 <- predict(pfit1, seedsvaluesTest, type = "class")
ppred2 <- predict(pfit2, seedsvaluesTest, type = "class")
ppred3 <- predict(pfit3, seedsvaluesTest, type = "class")
l = length(seedsclassTest)
lcor1 = sum(ppred1 == seedsclassTest)
lcor2 = sum(ppred2 == seedsclassTest)
lcor3 = sum(ppred3 == seedsclassTest)
lacc1 = lcor1/l #with a pruning parameter here, cp, set to 0.1
lacc2 = lcor2/l #with a pruning parameter here, cp, set to 0.3
lacc3 = lcor3/l #with a pruning parameter here, cp, set to 0.6
#declaring variables of decision tree
accuracyDT <- c(lacc1,lacc2,lacc3)
cpVAL <-c(0.1, 0.3, 0.6)
#plotting pruned tree
plot(pfit, uniform = TRUE, main="Pruned deision tree CP=0.1)")
text(pfit, use.n = TRUE, all = TRUE, cex =0.5)
#Task 3: Plot 2 variables (class and area)
plot(seedsclass, seeds_rand$Area, main = "Area against class", ylab="area", xlab = "seeds class", col = ifelse(seedsclass == 1, "green", ifelse(seedsclass == 2, "red", "blue")))
#Task 4:Compare the accuracy of the different pruned trees to KNN with different values of k
library(class)
#generating predicated classes k=number of clusters
knnpred1 = knn(seedsvaluesTrain, seedsvaluesTest, seedsclassTrain, k=1)
knnpred2 = knn(seedsvaluesTrain, seedsvaluesTest, seedsclassTrain, k=3)
knnpred3 = knn(seedsvaluesTrain, seedsvaluesTest, seedsclassTrain, k=6)
k = length(seedsclassTest)
kcor1 = sum(knnpred1 == seedsclassTest)
kcor2 = sum(knnpred2 == seedsclassTest)
kcor3 = sum(knnpred3 == seedsclassTest)
kacc1 = kcor1 / k
kacc2 = kcor2 / k
kacc3 = kcor3 / k
print(kacc1)
print(lacc2)
#declared variables of KNN
knnAccRes <- c(kacc1, kacc2, kacc3)
noClusters<- c(1,3,6)
#comparing knn and dynamic trees plots
plot(noClusters,knnAccRes, ylab = "k-nearest accuracy", xlab = "number of k-values", main = "accuracy against k-values")
plot(cpVAL, accuracyDT, ylab = "decision tree accuracy", xlab = "CP values", main="accuracy of pruned data")
source("~/ClusteringLab/lab 2.R", echo=TRUE)
#comparing knn and dynamic trees plots
plot(noClusters,knnAccRes, ylab = "k-nearest accuracy", xlab = "number of k-values", main = "accuracy against k-values")
View(seeds_rand)
lcor1 = sum(ppred1 == seedsclassTest)
seedsdata = read.csv('/Users/elias/Downloads/seeds_dataset_class (1).csv', sep=",")
#randomize - we do not want to train an ordered dataset, highly unlikely to get higher accuracy, no possibility of backtracking
seeds_rand=seedsdata[sample(209,209),]
#separate the class and values into separate variables
seedsclass = seeds_rand[,1]
seedsvalues = seeds_rand[,-1]
#set up a training set - split data into a larger portion for training
seedsclassTrain = seedsclass[1:150]
seedsvaluesTrain = seedsvalues[1:150,]
#and testset - split data into a smaller portion for testset
seedsclassTest = seedsclass[150:209]
seedsvaluesTest = seedsvalues[150:209,]
#building descision tree
#install.packages("rpart")
library(rpart)
fit <- rpart(seedsclassTrain~., method="class", data=seedsvaluesTrain) #model for decision tree
#Plot descision tree for seedsdata
plot(fit, uniform=TRUE, main="Decision Tree for Seedsdata")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
#classifier test / checking accuracy
treepred <-predict(fit, seedsvaluesTest, type = 'class')
n = length(seedsclassTest) #the number of test cases in the length of the testdata
ncorrect = sum(treepred==seedsclassTest) #the number of correctly predicted
accuracy=ncorrect/n
print(accuracy)
#viewing results as table
table_mat = table(seedsclassTest, treepred)
print(table_mat)
#vewing effect of pruning/plotting pruned dexision trees with a pruning parameter here, cp, set to 0.1
#REMOVING UNWANTED BRANCHES TO AVOID OVERFITTING
pfit1<- prune(fit, cp=0.1)
#vewing effect of pruning/with a pruning parameter here, cp, set to 0.3
pfit2<- prune(fit, cp=0.3)
#vewing effect of pruning/with a pruning parameter here, cp, set to 0.6
pfit3<- prune(fit, cp=0.6)
#testing the classifier on the test set by calculating the predictions for each testcase in our test set
ppred1 <- predict(pfit1, seedsvaluesTest, type = "class")
ppred2 <- predict(pfit2, seedsvaluesTest, type = "class")
ppred3 <- predict(pfit3, seedsvaluesTest, type = "class")
l = length(seedsclassTest)
lcor1 = sum(ppred1 == seedsclassTest)
lcor2 = sum(ppred2 == seedsclassTest)
lcor3 = sum(ppred3 == seedsclassTest)
lacc1 = lcor1/l #with a pruning parameter here, cp, set to 0.1
lacc2 = lcor2/l #with a pruning parameter here, cp, set to 0.3
lacc3 = lcor3/l #with a pruning parameter here, cp, set to 0.6
#declaring variables of decision tree
accuracyDT <- c(lacc1,lacc2,lacc3)
cpVAL <-c(0.1, 0.3, 0.6)
#plotting pruned tree
plot(pfit, uniform = TRUE, main="Pruned deision tree CP=0.1)")
text(pfit, use.n = TRUE, all = TRUE, cex =0.5)
#Task 3: Plot 2 variables (class and area)
plot(seedsclass, seeds_rand$Area, main = "Area against class", ylab="area", xlab = "seeds class", col = ifelse(seedsclass == 1, "green", ifelse(seedsclass == 2, "red", "blue")))
#Task 4:Compare the accuracy of the different pruned trees to KNN with different values of k
library(class)
#generating predicated classes k=number of clusters
knnpred1 = knn(seedsvaluesTrain, seedsvaluesTest, seedsclassTrain, k=1)
knnpred2 = knn(seedsvaluesTrain, seedsvaluesTest, seedsclassTrain, k=3)
knnpred3 = knn(seedsvaluesTrain, seedsvaluesTest, seedsclassTrain, k=6)
k = length(seedsclassTest)
kcor1 = sum(knnpred1 == seedsclassTest)
kcor2 = sum(knnpred2 == seedsclassTest)
kcor3 = sum(knnpred3 == seedsclassTest)
kacc1 = kcor1 / k
kacc2 = kcor2 / k
kacc3 = kcor3 / k
print(kacc1)
print(lacc2)
#declared variables of KNN
knnAccRes <- c(kacc1, kacc2, kacc3)
noClusters<- c(1,3,6)
#comparing knn and dynamic trees plots
plot(noClusters,knnAccRes, ylab = "k-nearest accuracy", xlab = "number of k-values", main = "accuracy against k-values")
plot(cpVAL, accuracyDT, ylab = "decision tree accuracy", xlab = "CP values", main="accuracy of pruned data")
treepred <-predict(fit, seedsvaluesTest, type = 'class')
n = length(seedsclassTest) #the number of test cases in the length of the testdata
ncorrect = sum(treepred==seedsclassTest) #the number of correctly predicted
accuracy=ncorrect/n
print(accuracy)
#viewing results as table - WHY WE USE THIS!!!!!!!!!!!!!!
table_mat = table(seedsclassTest, treepred)
print(table_mat)
source("~/ClusteringLab/lab 2.R", echo=TRUE)
View(seeds_rand)
source("~/ClusteringLab/lab 2.R", echo=TRUE)
source("~/ClusteringLab/lab 2.R", echo=TRUE)
source("~/ClusteringLab/lab1_script.R", echo=TRUE)
source("~/ClusteringLab/lab1_script.R", echo=TRUE)
source("~/ClusteringLab/lab1_script.R", echo=TRUE)
source("~/ClusteringLab/lab1_script.R", echo=TRUE)
source("~/ClusteringLab/lab1_script.R", echo=TRUE)
source("~/ClusteringLab/lab 2.R", echo=TRUE)
source("~/ClusteringLab/lab 2.R", echo=TRUE)
source("~/ClusteringLab/lab1_script.R", echo=TRUE)
source("~/ClusteringLab/lab 2.R", echo=TRUE)
print(kacc3)
seedsdata = read.csv('/Users/elias/Downloads/seeds_dataset_class (1).csv', sep=",")
#randomize - we do not want to train an ordered dataset,
# highly unlikely to get higher accuracy, no possibility of backtracking
seeds_rand=seedsdata[sample(209,209),]
#separate the class and values into separate variables
seedsclass = seeds_rand[,1]
seedsvalues = seeds_rand[,-1]
#set up a training set - split data into a larger portion for training
seedsclassTrain = seedsclass[1:150]
seedsvaluesTrain = seedsvalues[1:150,]
#and testset - split data into a smaller portion for testset
seedsclassTest = seedsclass[150:209]
seedsvaluesTest = seedsvalues[150:209,]
#building descision tree MODEL
#install rpart library for building classification and regression trees
library(rpart)
#creating a fit model (model for decision tree)
fit <- rpart(seedsclassTrain~., method="class", data=seedsvaluesTrain) #model for decision tree
#Plot descision tree for seedsdata
plot(fit, uniform=TRUE, main="Decision Tree for Seedsdata") #COULD ADD MORE MARGIN TO MAKE IT MORE READIBLE
text(fit, use.n=TRUE, all=TRUE, cex=.8)
#classifier test / checking accuracy OF DECISION TREE MODEL
treepred <-predict(fit, seedsvaluesTest, type = 'class') #USING PREDICT FUNCTION
n = length(seedsclassTest) #the number of test cases in the length of the testdata
ncorrect = sum(treepred==seedsclassTest) #the number of correctly predicted
accuracy=ncorrect/n #number of correctly predicted / length of test data
print(accuracy)
#viewing results as table - WHY WE USE THIS!!!!!!!!!!!!!!
table_mat = table(seedsclassTest, treepred)
print(table_mat)
#vewing effect of pruning/plotting pruned dexision trees with a pruning parameter here, cp, set to 0.1
#REMOVING UNWANTED BRANCHES TO AVOID OVERFITTING
pfit1<- prune(fit, cp=0.1)
#vewing effect of pruning/with a pruning parameter here, cp, set to 0.3
pfit2<- prune(fit, cp=0.3)
#vewing effect of pruning/with a pruning parameter here, cp, set to 0.6
pfit3<- prune(fit, cp=0.6)
#testing the classifier on the test set by calculating the predictions for each testcase in our test set
ppred1 <- predict(pfit1, seedsvaluesTest, type = "class")
ppred2 <- predict(pfit2, seedsvaluesTest, type = "class")
ppred3 <- predict(pfit3, seedsvaluesTest, type = "class")
l = length(seedsclassTest)
lcor1 = sum(ppred1 == seedsclassTest)
lcor2 = sum(ppred2 == seedsclassTest)
lcor3 = sum(ppred3 == seedsclassTest)
lacc1 = lcor1/l #with a pruning parameter here, cp, set to 0.1
lacc2 = lcor2/l #with a pruning parameter here, cp, set to 0.3
lacc3 = lcor3/l #with a pruning parameter here, cp, set to 0.6
#declaring variables of decision tree
accuracyDT <- c(lacc1,lacc2,lacc3)
cpVAL <-c(0.1, 0.3, 0.6)
#plotting pruned tree
plot(pfit, uniform = TRUE, main="Pruned deision tree CP=0.1)")
text(pfit, use.n = TRUE, all = TRUE, cex =0.5)
#Task 3: Plot 2 variables (class and area)
plot(seedsclass, seeds_rand$Area, main = "Comparison of area of three variants of wheat kernel (area against class)", ylab="area", xlab = "seeds class", col = ifelse(seedsclass == 1, "green", ifelse(seedsclass == 2, "red", "blue")))
#compares two different values to see the accuracy
#Task 4:Compare the accuracy of the different pruned trees to KNN with different values of k
library(class)
#generating predicated classes k=number of clusters
knnpred1 = knn(seedsvaluesTrain, seedsvaluesTest, seedsclassTrain, k=1)
knnpred2 = knn(seedsvaluesTrain, seedsvaluesTest, seedsclassTrain, k=3)
knnpred3 = knn(seedsvaluesTrain, seedsvaluesTest, seedsclassTrain, k=6)
k = length(seedsclassTest)
kcor1 = sum(knnpred1 == seedsclassTest)
kcor2 = sum(knnpred2 == seedsclassTest)
kcor3 = sum(knnpred3 == seedsclassTest)
kacc1 = kcor1 / k
kacc2 = kcor2 / k
kacc3 = kcor3 / k
print(kacc1)
print(kacc2)
print(kacc3)
print(lacc2)
#declared variables of KNN
knnAccRes <- c(kacc1, kacc2, kacc3)
noClusters<- c(1,3,6)
#comparing knn and dynamic trees plots
plot(noClusters,knnAccRes, ylab = "k-nearest accuracy", xlab = "number of k-values", main = "accuracy against k-values")
plot(cpVAL, accuracyDT, ylab = "decision tree accuracy", xlab = "CP values", main="accuracy of pruned data")
install.packages("neuralnet")
library(neuralnet)
#OR gate input data
trainin = rbind(c(1,1), c(1,-1), c(-1,1), c(-1,-1));
#OR gate output data
trainout = rbind(1, 1, 1, 0);
#Combined OR gate data
ORdat=cbind(trainout,trainin)
# fit neural network with no hidden layers
set.seed(2)
NN = neuralnet(ORdat[,1]~., ORdat[,-1], hidden = 0 , threshold = 0.001,
stepmax = 1e+05, linear.output = FALSE)
#visualise the NN
plot(NN)
NN$weights
testin= rbind(c(1,1))
predict_testNN = compute(NN, testin)
predict_testNN$net.result
predict_out = as.numeric(predict_testNN$net.result>0.5)
print(predict_out)
#set up the input sequence
testin=rbind(c(1,1),c(1,-1),c(-1,1), c(-1,-1))
predict_testNN = compute(NN, testin)
predict_testNN$neurons
predict_testNN$net.result
predict_out = as.numeric(predict_testNN$net.result>0.5)
predict_out
#XOR gate input data
trainin = rbind(c(-1,-1), c(1,-1), c(-1,1), c(1,1));
install.packages("neuralnet")
library(neuralnet)
#XOR gate input data
trainin = rbind(c(-1,-1), c(1,-1), c(-1,1), c(1,1));
#XOR gate output data
trainout = rbind(0, 1, 1, 0);
#Combined OR gate data
ORdat=cbind(trainout,trainin)
# fit neural network with no hidden layers
set.seed(2)
NN = neuralnet(ORdat[,1]~., ORdat[,-1], hidden = 0 , threshold = 0.001,
stepmax = 1e+05, linear.output = FALSE)
#visualise the NN
plot(NN)
NN$weights
testin= rbind(c(1,1))
predict_testNN = compute(NN, testin)
predict_testNN$net.result
predict_out = as.numeric(predict_testNN$net.result>0.5)
print(predict_out)
#set up the input sequence
testin=rbind(c(1,1),c(1,-1),c(-1,1), c(-1,-1))
predict_testNN = compute(NN, testin)
predict_testNN$neurons
predict_testNN$net.result
predict_out = as.numeric(predict_testNN$net.result>0.5)
predict_out
library(neuralnet)
library(neuralnet)
#XOR gate input data
trainin = rbind(c(-1,-1), c(1,-1), c(-1,1), c(1,1));
#XOR gate output data
trainout = rbind(0, 1, 1, 0);
#Combined OR gate data
ORdat=cbind(trainout,trainin)
# fit neural network with no hidden layers
set.seed(2)
NN = neuralnet(ORdat[,1]~., ORdat[,-1], hidden = 0 , threshold = 0.001,
stepmax = 1e+05, linear.output = FALSE)
#visualise the NN
plot(NN)
NN$weights
testin= rbind(c(1,1))
predict_testNN = compute(NN, testin)
predict_testNN$net.result
predict_out = as.numeric(predict_testNN$net.result>0.5)
print(predict_out)
#set up the input sequence
testin=rbind(c(1,1),c(1,-1),c(-1,1), c(-1,-1))
predict_testNN = compute(NN, testin)
predict_testNN$neurons
predict_testNN$net.result
predict_out = as.numeric(predict_testNN$net.result>0.5)
predict_out
NN = neuralnet(ORdat[,1]~., ORdat[,-1], hidden = c(3,3) , threshold = 0.001,
stepmax = 1e+05, linear.output = FALSE)
library(neuralnet)
#XOR gate input data
trainin = rbind(c(-1,-1), c(1,-1), c(-1,1), c(1,1));
#XOR gate output data
trainout = rbind(0, 1, 1, 0);
#Combined OR gate data
ORdat=cbind(trainout,trainin)
# fit neural network with no hidden layers
set.seed(2)
NN = neuralnet(ORdat[,1]~., ORdat[,-1], hidden = c(3,3) , threshold = 0.001,
stepmax = 1e+05, linear.output = FALSE)
#visualise the NN
plot(NN)
NN$weights
testin= rbind(c(1,1))
predict_testNN = compute(NN, testin)
predict_testNN$net.result
predict_out = as.numeric(predict_testNN$net.result>0.5)
print(predict_out)
#set up the input sequence
testin=rbind(c(1,1),c(1,-1),c(-1,1), c(-1,-1))
predict_testNN = compute(NN, testin)
predict_testNN$neurons
predict_testNN$net.result
predict_out = as.numeric(predict_testNN$net.result>0.5)
predict_out
library(neuralnet)
#XOR gate input data
trainin = rbind(c(-1,-1), c(1,-1), c(-1,1), c(1,1));
#XOR gate output data
trainout = rbind(0, 1, 1, 0);
#Combined OR gate data
ORdat=cbind(trainout,trainin)
# fit neural network with no hidden layers
set.seed(2)
NN = neuralnet(ORdat[,1]~., ORdat[,-1], hidden = c(3,3) , threshold = 0.001,
stepmax = 1e+05, linear.output = FALSE)
#visualise the NN
plot(NN)
NN$weights
testin= rbind(c(1,1))
predict_testNN = compute(NN, testin)
predict_testNN$net.result
predict_out = as.numeric(predict_testNN$net.result>0.5)
print(predict_out)
#set up the input sequence
testin=rbind(c(1,1),c(1,-1),c(-1,1), c(-1,-1))
predict_testNN = compute(NN, testin)
predict_testNN$neurons
predict_testNN$net.result
predict_out = as.numeric(predict_testNN$net.result>0.5)
predict_out
library(neuralnet)
#XOR gate input data
trainin = rbind(c(-1,-1), c(1,-1), c(-1,1), c(1,1));
#XOR gate output data
trainout = rbind(0, 1, 1, 0);
#Combined OR gate data
ORdat=cbind(trainout,trainin)
# fit neural network with no hidden layers
set.seed(2)
# adding 2 hidden layers, and 3 neuons each
NN = neuralnet(ORdat[,1]~., ORdat[,-1], hidden = c(2,2) , threshold = 0.001,
stepmax = 1e+05, linear.output = FALSE)
#visualise the NN
plot(NN)
NN$weights
testin= rbind(c(1,1))
predict_testNN = compute(NN, testin)
predict_testNN$net.result
predict_out = as.numeric(predict_testNN$net.result>0.5)
print(predict_out)
#set up the input sequence
testin=rbind(c(1,1),c(1,-1),c(-1,1), c(-1,-1))
predict_testNN = compute(NN, testin)
predict_testNN$neurons
predict_testNN$net.result
predict_out = as.numeric(predict_testNN$net.result>0.5)
predict_out
library(neuralnet)
#XOR gate input data
trainin = rbind(c(-1,-1), c(1,-1), c(-1,1), c(1,1));
#XOR gate output data
trainout = rbind(0, 1, 1, 0);
#Combined OR gate data
ORdat=cbind(trainout,trainin)
# fit neural network with no hidden layers
set.seed(2)
# adding 2 hidden layers, and 3 neuons each
NN = neuralnet(ORdat[,1]~., ORdat[,-1], hidden = c(5,5) , threshold = 0.001,
stepmax = 1e+05, linear.output = FALSE)
#visualise the NN
plot(NN)
NN$weights
testin= rbind(c(1,1))
predict_testNN = compute(NN, testin)
predict_testNN$net.result
predict_out = as.numeric(predict_testNN$net.result>0.5)
print(predict_out)
#set up the input sequence
testin=rbind(c(1,1),c(1,-1),c(-1,1), c(-1,-1))
predict_testNN = compute(NN, testin)
predict_testNN$neurons
predict_testNN$net.result
predict_out = as.numeric(predict_testNN$net.result>0.5)
predict_out
plot(trainin)
